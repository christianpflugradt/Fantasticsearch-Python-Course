# 1B - download all JEPs

Difficulty: 3/5

Improve upon the `crawl` function.

`crawl` should parse all JEPs from the JEP index, download all of them
and return a list of tuples for all JEPs (id, title, content) where id is the JEP number,
title is the name of the JEP and content the html page of the JEP.

You are given the following regular expression to extract all JEP ids from the JEP index:
`jepmatch = r'<td class="jep">(\d+)</td>'`

You are given the following regular expression to extract the JEP title from the JEP html page:
`titlematch = r'<title>(.+)</title>'`

You should use the `re` module to apply regular expressions.

## Interface ##

File: [crawler.py](workspace/crawler.py)

Function name: `crawl`

Parameters: none

Return value: a list of tuples for all JEPs (id, title, content) 

## Tips ##

<details>
  <summary>show tips</summary>

* try to import `re` in your REPL, then inspect it with `dir()`
* `findall(match, content)` will return a list of strings matching `match` in `content`
* you should remove all line breaks `\n` and `\r` before applying the regex 
  because it will not match across multiple lines
* `'Python'.replace('P', 'J') == 'Jython'`  
* `[1].append(2) == [1,2]`
</details>

## Solution ##

<details>
  <summary>show solution</summary>

```
from re import findall
from urllib.request import urlopen

jepbaseurl = 'http://openjdk.java.net/jeps/'
jepmatch = r'<td class="jep">(\d+)</td>'
titlematch = r'<title>(.+)</title>'

def get_jep(id):
    return str(urlopen('%s%s' % (jepbaseurl, str(id))).read()).replace('\\n',' ').replace('\\r',' ')
    
def download_jep(id):
    content = get_jep(id)
    if content is not None:
        title = findall(titlematch, content)[0]
        return (id, title, content)

def crawl():
    jepdb = []
    jepindex = get_jep(0)
    hits = findall(jepmatch, jepindex)
    for hit in hits:
        jepdb.append(download_jep(hit))
    return jepdb
```
</details>

## Navigation ##
* [back to overview](0.md)
