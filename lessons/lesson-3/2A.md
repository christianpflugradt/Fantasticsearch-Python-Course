# 2A - find relevant text in content

Difficulty: 1/5

Implement the ```tokenize``` function.

```tokenize``` is called for each JEP and should return a list of tokens (words) contained in that JEP.

For now, we only want to find relevant parts of the html content and return it as a list of string.

You are given two regular expressions below that will extract relevant content from the document:
```
textmatch = r'<h2 id=.+?>.+?</h2>(.+?)<h2>'
finaltextmatch = r'<h2 id=.+?>.+?</h2>(.+?)</div>'
```

Use the ```re``` and these regular expressions to find all relevant content and return it as a list of strings.

## Interface ##

File: [tokenizer.py](workspace/tokenizer.py)

Function name: ```tokenize```

Parameters: html content of the JEP as string

Return value: list of strings where each string contains a relevant part of the html content

## Tips ##

<details>
  <summary>show tips</summary>

* * try to import ```re``` in your REPL, then inspect it with ```dir()```
* ```findall(match, content)``` will return a list of strings matching ```match``` in ```content```
* you can concat two lists with the ```+``` operator: ```[1] + [2] == [1,2]```
</details>

## Solution ##

<details>
  <summary>show solution</summary>

```
from re import findall

textmatch = r'<h2 id=.+?>.+?</h2>(.+?)<h2>'
finaltextmatch = r'<h2 id=.+?>.+?</h2>(.+?)</div>'

def tokenize(content):
	return findall(textmatch, content) + findall(finaltextmatch, content)
```
</details>

## Navigation ##
* [back to overview](0.md)
