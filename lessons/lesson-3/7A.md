# 7A - improve JEP download speed

Difficulty: 3/5

You must have at least finished sub lessons 1A and 1B before starting this one,
but it's recommended to have finished all previous sub lessons beforehand.

Improve upon the `crawl` function. Start a new thread for every JEP download.
Do not limit the maximum number of active threads. Only return the result once
all threads have finished downloading their JEPs. If an error occurs downloading
the JEP print the following to `stdout`: `could not download jep :-(`

You should use the `threading` module to start threads.

Implement `get_number_of_threads` and `wait_until_threshold_reached`
in [concurrency.py](workspace/concurrency.py) and use these
to improve the `crawl` function.
You'll also need these functions in the next sub lesson.

## Interface ##

Files:
* [crawler.py](workspace/crawler.py)
* [concurrency.py](workspace/concurrency.py)

Function names:
* `crawl`
* `get_number_of_threads`
* `wait_until_threshold_reached`

Parameters:
* `crawl`: *unchanged*
* `get_number_of_threads`: none
* `wait_until_threshold_reached`: the number of threads 
  that should exist at most before this function stops blocking

Return value:
* `crawl`: *unchanged*
* `get_number_of_threads`: the number of threads
* `wait_until_threshold_reached`: none

## Tips ##

<details>
  <summary>show tips</summary>

* try to import `threading` in your REPL, then inspect it with `dir()`
* `active_count()` will return the number of active threads
* `time.sleep(1)` puts the current thread to sleep for one second
* `Thread(target=print, args=("hello, world!",)).start()` starts a new thread
    that prints `hello, world!` to `stdout`
* threads can update shared resources without any special declarations,
    as we're only appending items to a list, we do not need to worry about race conditions
* catch all errors:
```
try:
    pass # do something here
except:
    pass # handle all errors here
```
* `==` and `!=` check equality, while `is` and `is not` check object identity
* as `None` is a singleton object, it is better to compare against `None`
    using `is` rather than `==`
</details>

## Solution ##

<details>
  <summary>show solution</summary>

```
# concurrency.py

from threading import active_count as count
from time import sleep

def get_number_of_threads():
    return count()

def wait_until_threshold_reached(threshold):
    sleep(1)
    threads = count()
    while threads > threshold:
        threads = count()
        print('still waiting for %d threads' % threads)
        sleep(1)

# crawler.py

from concurrency import get_number_of_threads as count
from concurrency import wait_until_threshold_reached as wait_for
from re import findall
from urllib.request import urlopen
from threading import Thread

jepbaseurl = 'http://openjdk.java.net/jeps/'
jepmatch = r'<td class="jep">(\d+)</td>'
titlematch = r'<title>(.+)</title>'

jepdb = []

def get_jep(id):
    try:
        return str(urlopen('%s%s' % (jepbaseurl, str(id))).read()).replace('\\n',' ').replace('\\r',' ')
    except:
        print('could not download jep :-(')
        return None

def download_jep(id):
    content = get_jep(id)
    if content is not None:
        title = findall(titlematch, content)[0]
        jepdb.append((id, title, content))

def crawl_all_jeps():
    jepindex = get_jep(0)
    hits = findall(jepmatch, jepindex)
    for hit in hits:
        Thread(target=download_jep, args=(hit,)).start()

def crawl():
    threshold = count()
    crawl_all_jeps()
    wait_for(threshold)
    return jepdb
```
</details>

## Navigation ##
* [back to overview](0.md)
